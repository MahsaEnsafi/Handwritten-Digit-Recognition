# -*- coding: utf-8 -*-
"""handwritten recognition.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1TlVasu5BM3ZKZ0fNJmoKcm4Zylab611l
"""
# Mount Google Drive 
from google.colab import drive 
drive.mount('/content/drive')
#--------------------------------------------------------------------------------

# Import necessary libraries
import tensorflow as tf
from tensorflow.keras import models,layers,losses,callbacks
from sklearn.metrics import confusion_matrix,classification_report
import matplotlib.pyplot as plt
import numpy as np
import seaborn as sn
#----------------------------------------------------------------------------------

# Load the MNIST dataset
(x_train,y_train),(x_test,y_test)=tf.keras.datasets.mnist.load_data()
print(x_train.shape) ## Display the shape of the training set
#----------------------------------------------------------------------------------

# Reshape the data to include a channel dimension
x_train = x_train.reshape(-1, 28, 28, 1) # Reshape for CNN input
x_test = x_test.reshape(-1, 28, 28, 1)
print(x_train.shape) # Print the new shape of the training data
#-----------------------------------------------------------------------------------

# Visualize a sample image from the test set
plt.matshow(x_test[9])  # Display the 10th test image
print(y_test[9]) # Print the true label for this image
#------------------------------------------------------------------------------------

# Normalize the pixel values to the range [0, 1]
x_train=x_train/255
x_test=x_test/255
print('shapee of x_train:',x_train.shape) # Print the shape of the training data
print('shapee of x_test:',x_test.shape) # Print the shape of the test data
#-------------------------------------------------------------------------------------

# Data augmentation to enhance model robustness
data_aug=tf.keras.Sequential([
    layers.RandomZoom(0.3),
    layers.RandomFlip("horizontal_and_vertical"),
    layers.RandomRotation(0.2),
])
#--------------------------------------------------------------------------------------

# Function to create and compile the model
def my_model():
  model=models.Sequential([
      data_aug,
      layers.Conv2D(filters=32,kernel_size=(3,3),activation='relu',input_shape=(28,28,1)),
      layers.MaxPool2D((2,2)),
      layers.Conv2D(filters=64,kernel_size=(3,3),activation='relu'),
      layers.MaxPool2D((2,2)),
      layers.Flatten(),
      layers.Dense(256,activation='relu'),
      layers.Dropout(0.5),
      layers.Dense(128,activation='relu'),
      layers.Dropout(0.5),
      layers.Dense(64,activation='relu'),
      layers.Dropout(0.5),
      layers.Dense(32,activation='relu'),
      layers.Dense(10,activation='softmax')
  ])
  model.compile(
      optimizer='adam',
      loss=losses.sparse_categorical_crossentropy,
      metrics=['accuracy']
  )
  return model
  

# Function to evaluate the model
def eval(model, X, Y):
    model.evaluate(X, Y)

# Function for making predictions
def prediction(model, X, Y):
    Y_predict = model.predict(X)
    Y_pred = [np.argmax(i) for i in Y_predict]  
    print('Predicted the first five labels:', Y_pred[:5])
    print('True labels of the first five elements:', Y[:5])
    return Y_pred

# Function to display classification report and confusion matrix
def report(truth, predictions):
    print(classification_report(truth, predictions))
    cm = tf.math.confusion_matrix(labels=truth, predictions=predictions)
    plt.figure(figsize=(10, 7))
    sn.heatmap(cm, annot=True, fmt='d')
    plt.xlabel('Predicted')
    plt.ylabel('Truth')

# Function to plot training and validation loss
def plot_loss(history):
    plt.figure(figsize=(10, 6))
    plt.plot(history.history['loss'], label='Train Loss')
    plt.plot(history.history['val_loss'], label='Validation Loss')
    plt.title('Training and Validation Loss')
    plt.xlabel('Epochs')
    plt.ylabel('Loss')
    plt.legend()
    plt.grid()
    plt.show()

# Function to plot training and validation accuracy
def plot_accuracy(history):
    plt.figure(figsize=(10, 6))
    plt.plot(history.history['accuracy'], label='Train Accuracy')
    plt.plot(history.history['val_accuracy'], label='Validation Accuracy')
    plt.title('Training and Validation Accuracy')
    plt.xlabel('Epochs')
    plt.ylabel('Accuracy')
    plt.legend()
    plt.grid()
    plt.show()
#-----------------------------------------------------------------------------------------------------------

# Create and train the model
model=my_model() # Instantiate the model
tb_callback=callbacks.TensorBoard(log_dir='/logs',histogram_freq=1) # Set up TensorBoard callback
history=model.fit(x_train,y_train,epochs=50,validation_split=0.2,callbacks=tb_callback) # Train the model
#-----------------------------------------------------------------------------------------------------------

# Plot training and validation loss and accuracy
plot_loss(history)
plot_accuracy(history)
#---------------------------------------------------------------------------------------------------------

# Evaluate the model on the test set
eval(model,x_test,y_test)
#----------------------------------------------------------------------------------------------------------

# Make predictions
preds=prediction(model,x_test,y_test)
#---------------------------------------------------------------------------------------------------------

#Generate a report
report(y_test,preds)
